{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec :- \n",
    "## The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text.Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence. As the name implies,word2vec represents each distinct word with a particular list of numbers called a vector. \n",
    "## The vectors are chosen carefully such that a simple mathematical function (the cosine similarity between the vectors) indicates the level of semantic similarity between the words represented by those vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we perform word2vec on the famous speech given by Swami Vivekananda at Parliment of religion held in chicago sept 11 1893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "paragraph = \"\"\"Sisters and Brothers of America,\n",
    "It fills my heart with joy unspeakable to rise in response to the warm and cordial welcome which you have given us. \n",
    "I thank you in the name of the most ancient order of monks in the world, I thank you in the name of the mother of religions,\n",
    "and I thank you in the name of millions and millions of Hindu people of all classes and sects.\n",
    "My thanks, also, to some of the speakers on this platform who, referring to the delegates from the Orient, \n",
    "have told you that these men from far-off nations may well claim the honor of bearing to different lands the idea of toleration. \n",
    "I am proud to belong to a religion which has taught the world both tolerance and universal acceptance. We believe not only in universal toleration, but we accept all religions as true. \n",
    "I am proud to belong to a nation which has sheltered the persecuted and the refugees of all religions and all nations of the earth. \n",
    "I am proud to tell you that we have gathered in our bosom the purest remnant of the Israelites, \n",
    "who came to Southern India and took refuge with us in the very year in which their holy temple was shattered to pieces by Roman tyranny. \n",
    "I am proud to belong to the religion which has sheltered and is still fostering the remnant of the grand Zoroastrian nation. \n",
    "I will quote to you, brethren, a few lines from a hymn which I remember to have repeated from my earliest boyhood, \n",
    "which is every day repeated by millions of human beings: “As the different streams having their sources in different paths which men take through different tendencies, \n",
    "various though they appear, crooked or straight, all lead to Thee.”\n",
    "The present convention, which is one of the most august assemblies ever held,is in itself a vindication, \n",
    "a declaration to the world of the wonderful doctrine preached in the Gita: “Whosoever comes to Me, through whatsoever form, \n",
    "I reach him; all men are struggling through paths which in the end lead to me.” Sectarianism, bigotry, and its horrible descendant, \n",
    "fanaticism, have long possessed this beautiful earth. They have filled the earth with violence, drenched it often and often with human blood, destroyed civilization and sent whole nations to despair. \n",
    "Had it not been for these horrible demons, human society would be far more advanced than it is now. But their time is come; \n",
    "and I fervently hope that the bell that tolled this morning in honor of this convention may be the death-knell of all fanaticism, of all persecutions with the sword or with the pen, \n",
    "and of all uncharitable feelings between persons wending their way to the same goal.\"\"\"\n",
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "\n",
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]\n",
    "    \n",
    "    \n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "\n",
    "words = model.wv.vocab\n",
    "\n",
    "# Finding Word Vectors\n",
    "vector = model.wv['india']\n",
    "\n",
    "# Most similar words\n",
    "similar = model.wv.most_similar('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4606275e-03,  3.3140806e-03,  2.5144280e-03, -4.6434645e-03,\n",
       "        1.0305485e-03,  9.4210316e-04,  5.2064733e-04,  2.7953614e-03,\n",
       "        1.6691411e-03, -4.2540017e-03,  1.8832535e-03, -2.3926031e-03,\n",
       "       -4.3887589e-03, -4.4760541e-03,  4.7343262e-03, -4.8477440e-03,\n",
       "        1.2869232e-03, -1.7638454e-03, -4.4403709e-03,  1.2439544e-03,\n",
       "        3.3083211e-03, -4.1373107e-03,  3.2276129e-03,  1.4862572e-03,\n",
       "       -1.8710509e-03, -4.3798722e-03, -4.7377697e-03,  2.2762232e-03,\n",
       "        3.8614974e-03,  1.1209121e-03, -2.5384161e-03, -3.8425266e-03,\n",
       "       -6.9574933e-05,  1.3314615e-04, -4.1918489e-03, -2.9494704e-03,\n",
       "        3.4443787e-03,  4.9357451e-03,  4.4149407e-03,  4.8807566e-03,\n",
       "        3.4160712e-03, -4.1335272e-03, -4.8693656e-03, -2.2922752e-04,\n",
       "       -2.3732411e-03, -1.5887324e-03,  3.1110044e-03, -4.9698949e-03,\n",
       "       -3.2519745e-03,  2.2055542e-03, -1.5644259e-03,  1.7512517e-04,\n",
       "        8.8125336e-05, -2.5748205e-03,  2.4547002e-03, -3.5112975e-03,\n",
       "        6.3536502e-04, -2.5357248e-03, -4.7293757e-03, -2.0206992e-03,\n",
       "        6.5243285e-04,  4.5551518e-03,  2.8343918e-03, -1.5748506e-03,\n",
       "        3.2205111e-03,  3.3361879e-03, -3.5752410e-03,  2.2899844e-03,\n",
       "        7.5365364e-04, -1.1925873e-03, -6.0206407e-04,  2.2307800e-03,\n",
       "        3.5585214e-03,  3.9306618e-03,  6.8093039e-04,  4.5198463e-03,\n",
       "        1.5409415e-03, -3.7513976e-03,  4.3605412e-03, -2.8966104e-03,\n",
       "       -1.6601741e-03,  2.1164238e-03, -1.9729226e-03,  3.3346103e-03,\n",
       "       -3.4185903e-04, -4.9368321e-04, -2.5993583e-03,  3.4788400e-03,\n",
       "        4.2643873e-03,  3.0613842e-03,  3.6563906e-03,  3.5401077e-03,\n",
       "        2.7543129e-03,  1.1489983e-03, -3.8016855e-04,  4.3506181e-04,\n",
       "        2.3679051e-04,  1.7337871e-03,  2.7755573e-03, -4.7669327e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accept', 0.23353859782218933),\n",
       " ('warm', 0.22713251411914825),\n",
       " ('remember', 0.21287193894386292),\n",
       " ('bell', 0.20619729161262512),\n",
       " ('demons', 0.2056163251399994),\n",
       " ('earth', 0.20189037919044495),\n",
       " ('long', 0.1937800496816635),\n",
       " ('descendant', 0.19169414043426514),\n",
       " ('claim', 0.18074330687522888),\n",
       " ('persons', 0.17353196442127228)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
